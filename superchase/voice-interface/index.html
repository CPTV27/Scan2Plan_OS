<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SuperChase Voice Assistant</title>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --success: #10b981;
            --danger: #ef4444;
            --dark: #1e293b;
            --darker: #0f172a;
            --gray: #94a3b8;
            --light: #e2e8f0;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, var(--darker) 0%, var(--dark) 100%);
            color: var(--light);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        /* Header */
        header {
            padding: 20px;
            text-align: center;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }

        header h1 {
            font-size: 1.5rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: var(--gray);
            transition: background 0.3s;
        }

        .status-dot.connected {
            background: var(--success);
            box-shadow: 0 0 10px var(--success);
        }

        .status-dot.speaking {
            background: var(--primary);
            box-shadow: 0 0 10px var(--primary);
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.2); }
        }

        /* Main Content */
        main {
            flex: 1;
            display: flex;
            flex-direction: column;
            padding: 20px;
            max-width: 800px;
            margin: 0 auto;
            width: 100%;
        }

        /* Conversation Display */
        #conversation {
            flex: 1;
            overflow-y: auto;
            padding: 20px 0;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .message {
            max-width: 85%;
            padding: 15px 20px;
            border-radius: 20px;
            line-height: 1.5;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: var(--primary);
            align-self: flex-end;
            border-bottom-right-radius: 5px;
        }

        .message.assistant {
            background: rgba(255,255,255,0.1);
            align-self: flex-start;
            border-bottom-left-radius: 5px;
        }

        .message.system {
            background: rgba(245, 158, 11, 0.2);
            border: 1px solid rgba(245, 158, 11, 0.3);
            align-self: center;
            font-size: 0.9rem;
            color: var(--gray);
        }

        /* Voice Button */
        #voice-controls {
            padding: 30px 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        #voice-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, var(--primary) 0%, var(--primary-dark) 100%);
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 10px 40px rgba(99, 102, 241, 0.3);
        }

        #voice-button:hover {
            transform: scale(1.05);
        }

        #voice-button:active {
            transform: scale(0.95);
        }

        #voice-button.listening {
            background: linear-gradient(135deg, var(--success) 0%, #059669 100%);
            box-shadow: 0 10px 40px rgba(16, 185, 129, 0.4);
            animation: listening 1.5s infinite;
        }

        @keyframes listening {
            0%, 100% { box-shadow: 0 10px 40px rgba(16, 185, 129, 0.4); }
            50% { box-shadow: 0 10px 60px rgba(16, 185, 129, 0.6); }
        }

        #voice-button.processing {
            background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
            box-shadow: 0 10px 40px rgba(245, 158, 11, 0.4);
        }

        #voice-button:disabled {
            background: var(--gray);
            cursor: not-allowed;
            box-shadow: none;
        }

        #status-text {
            color: var(--gray);
            font-size: 0.9rem;
        }

        /* Visualizer */
        #visualizer {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            height: 40px;
            margin-top: 10px;
        }

        .bar {
            width: 4px;
            height: 10px;
            background: var(--primary);
            border-radius: 2px;
            transition: height 0.1s;
        }

        /* Settings Panel */
        #settings-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255,255,255,0.1);
            border: none;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 10px;
            cursor: pointer;
            font-size: 1.2rem;
        }

        #settings-panel {
            position: fixed;
            top: 0;
            right: -400px;
            width: 350px;
            height: 100%;
            background: var(--darker);
            border-left: 1px solid rgba(255,255,255,0.1);
            padding: 20px;
            transition: right 0.3s;
            overflow-y: auto;
            z-index: 100;
        }

        #settings-panel.open {
            right: 0;
        }

        #settings-panel h2 {
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        #settings-panel .close-btn {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
        }

        .setting-group {
            margin-bottom: 25px;
        }

        .setting-group label {
            display: block;
            color: var(--gray);
            font-size: 0.85rem;
            margin-bottom: 8px;
        }

        .setting-group input,
        .setting-group select,
        .setting-group textarea {
            width: 100%;
            padding: 12px;
            border-radius: 8px;
            border: 1px solid rgba(255,255,255,0.2);
            background: rgba(255,255,255,0.05);
            color: white;
            font-size: 0.95rem;
        }

        .setting-group input:focus,
        .setting-group select:focus,
        .setting-group textarea:focus {
            outline: none;
            border-color: var(--primary);
        }

        .setting-group textarea {
            min-height: 150px;
            resize: vertical;
        }

        .save-btn {
            width: 100%;
            padding: 15px;
            background: var(--primary);
            border: none;
            border-radius: 8px;
            color: white;
            font-weight: 600;
            cursor: pointer;
            margin-top: 20px;
        }

        .save-btn:hover {
            background: var(--primary-dark);
        }

        /* Quick Actions */
        #quick-actions {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-bottom: 20px;
        }

        .quick-action {
            background: rgba(255,255,255,0.1);
            border: 1px solid rgba(255,255,255,0.2);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 0.85rem;
            transition: background 0.2s;
        }

        .quick-action:hover {
            background: rgba(255,255,255,0.2);
        }

        /* Mobile */
        @media (max-width: 600px) {
            #settings-panel {
                width: 100%;
                right: -100%;
            }

            #voice-button {
                width: 100px;
                height: 100px;
                font-size: 2.5rem;
            }

            .message {
                max-width: 90%;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>
            <span class="status-dot" id="status-dot"></span>
            SuperChase Voice
        </h1>
    </header>

    <button id="settings-toggle">‚öôÔ∏è</button>

    <main>
        <div id="conversation">
            <div class="message system">
                Configure your ElevenLabs API key in settings, then tap the microphone to start talking.
            </div>
        </div>

        <div id="quick-actions">
            <button class="quick-action" data-prompt="What's on my task list today?">My tasks</button>
            <button class="quick-action" data-prompt="Summarize my active projects">Projects</button>
            <button class="quick-action" data-prompt="Any leads I should follow up on?">Leads</button>
            <button class="quick-action" data-prompt="What contracts are pending?">Contracts</button>
            <button class="quick-action" data-prompt="Give me a status report">Status</button>
        </div>

        <div id="voice-controls">
            <button id="voice-button" disabled>üé§</button>
            <div id="visualizer">
                <div class="bar"></div>
                <div class="bar"></div>
                <div class="bar"></div>
                <div class="bar"></div>
                <div class="bar"></div>
                <div class="bar"></div>
                <div class="bar"></div>
            </div>
            <span id="status-text">Enter API key to start</span>
        </div>
    </main>

    <div id="settings-panel">
        <h2>
            Settings
            <button class="close-btn" id="close-settings">&times;</button>
        </h2>

        <div class="setting-group">
            <label>ElevenLabs API Key</label>
            <input type="password" id="elevenlabs-key" placeholder="sk_...">
        </div>

        <div class="setting-group">
            <label>Voice ID (optional - uses default if empty)</label>
            <input type="text" id="voice-id" placeholder="21m00Tcm4TlvDq8ikWAM">
        </div>

        <div class="setting-group">
            <label>Agent ID (for Conversational AI)</label>
            <input type="text" id="agent-id" placeholder="Your ElevenLabs Agent ID">
        </div>

        <div class="setting-group">
            <label>System Prompt (SuperChase Context)</label>
            <textarea id="system-prompt">You are SuperChase, an AI personal assistant for Chase Pierson at CPTV Inc.

SYSTEM CONTEXT:
- Database: Google Sheets (ID: 1mBfl_0f6MQ0RjezYmwt4bT6m2sMESzwWdxnmFzrRTY4)
- Task Management: 5 Asana projects that sync every 10 minutes
  - SC: Tasks (daily tasks)
  - SC: Projects (larger initiatives)
  - SC: Leads (sales pipeline)
  - SC: Contracts (contract lifecycle)
  - SC: Expenses (expense tracking)

YOUR CAPABILITIES:
1. Researcher Agent - Deep research, market analysis
2. Implementer Agent - Code, automation, integrations
3. Reviewer Agent - Quality assurance, document review
4. Communicator Agent - Email drafts, client responses
5. Strategist Agent - Business strategy, planning

BEHAVIOR:
- Be concise and actionable in voice responses
- Confirm task creation with brief acknowledgment
- For complex requests, break into steps
- Ask clarifying questions when needed
- Low-risk actions (research, drafts) execute automatically
- High-risk actions (sending emails, financial) require approval

Speak naturally and conversationally. You're Chase's trusted assistant.</textarea>
        </div>

        <button class="save-btn" id="save-settings">Save & Connect</button>
    </div>

    <script>
        // State
        let conversation = null;
        let isConnected = false;
        let isListening = false;
        let mediaRecorder = null;
        let audioContext = null;

        // DOM Elements
        const voiceButton = document.getElementById('voice-button');
        const statusText = document.getElementById('status-text');
        const statusDot = document.getElementById('status-dot');
        const conversationEl = document.getElementById('conversation');
        const settingsPanel = document.getElementById('settings-panel');
        const settingsToggle = document.getElementById('settings-toggle');
        const closeSettings = document.getElementById('close-settings');
        const saveSettings = document.getElementById('save-settings');
        const bars = document.querySelectorAll('.bar');

        // Load saved settings
        function loadSettings() {
            const saved = localStorage.getItem('superchase-voice-settings');
            if (saved) {
                const settings = JSON.parse(saved);
                document.getElementById('elevenlabs-key').value = settings.apiKey || '';
                document.getElementById('voice-id').value = settings.voiceId || '';
                document.getElementById('agent-id').value = settings.agentId || '';
                document.getElementById('system-prompt').value = settings.systemPrompt || document.getElementById('system-prompt').value;

                if (settings.apiKey) {
                    initializeVoice();
                }
            }
        }

        // Save settings
        function saveSettingsToStorage() {
            const settings = {
                apiKey: document.getElementById('elevenlabs-key').value,
                voiceId: document.getElementById('voice-id').value,
                agentId: document.getElementById('agent-id').value,
                systemPrompt: document.getElementById('system-prompt').value
            };
            localStorage.setItem('superchase-voice-settings', JSON.stringify(settings));
        }

        // Initialize voice connection
        async function initializeVoice() {
            const apiKey = document.getElementById('elevenlabs-key').value;
            const agentId = document.getElementById('agent-id').value;

            if (!apiKey) {
                addMessage('system', 'Please enter your ElevenLabs API key in settings.');
                return;
            }

            statusText.textContent = 'Connecting...';
            voiceButton.disabled = true;

            try {
                // If using ElevenLabs Conversational AI (recommended)
                if (agentId) {
                    await initConversationalAI(apiKey, agentId);
                } else {
                    // Fallback to basic TTS/STT mode
                    await initBasicMode(apiKey);
                }
            } catch (error) {
                console.error('Init error:', error);
                addMessage('system', `Connection failed: ${error.message}`);
                statusText.textContent = 'Connection failed';
            }
        }

        // ElevenLabs Conversational AI mode
        async function initConversationalAI(apiKey, agentId) {
            // Load the ElevenLabs SDK
            if (!window.ElevenLabs) {
                addMessage('system', 'Loading ElevenLabs SDK...');
                await loadScript('https://cdn.jsdelivr.net/npm/@11labs/client@latest/dist/index.umd.min.js');
            }

            const { Conversation } = window.ElevenLabs || {};

            if (!Conversation) {
                throw new Error('ElevenLabs SDK not loaded. Using fallback mode.');
            }

            conversation = await Conversation.startSession({
                agentId: agentId,
                authorization: apiKey,
                onMessage: (message) => {
                    if (message.type === 'agent') {
                        addMessage('assistant', message.text);
                    } else if (message.type === 'user') {
                        addMessage('user', message.text);
                    }
                },
                onStatusChange: (status) => {
                    updateStatus(status);
                },
                onError: (error) => {
                    console.error('Conversation error:', error);
                    addMessage('system', `Error: ${error.message}`);
                }
            });

            isConnected = true;
            voiceButton.disabled = false;
            statusDot.classList.add('connected');
            statusText.textContent = 'Ready - tap to talk';
            addMessage('system', 'Connected to SuperChase Voice. Tap the microphone to start.');
        }

        // Basic mode (TTS + browser STT)
        async function initBasicMode(apiKey) {
            // Check for speech recognition support
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                throw new Error('Speech recognition not supported in this browser');
            }

            isConnected = true;
            voiceButton.disabled = false;
            statusDot.classList.add('connected');
            statusText.textContent = 'Ready - tap to talk';
            addMessage('system', 'Connected in basic mode. Tap the microphone to start.');
        }

        // Load external script
        function loadScript(src) {
            return new Promise((resolve, reject) => {
                const script = document.createElement('script');
                script.src = src;
                script.onload = resolve;
                script.onerror = reject;
                document.head.appendChild(script);
            });
        }

        // Toggle listening
        async function toggleListening() {
            if (!isConnected) return;

            if (conversation) {
                // Conversational AI mode
                if (isListening) {
                    await conversation.endSession();
                    isListening = false;
                    voiceButton.classList.remove('listening');
                    statusText.textContent = 'Ended';
                } else {
                    isListening = true;
                    voiceButton.classList.add('listening');
                    statusText.textContent = 'Listening...';
                }
            } else {
                // Basic mode with browser speech recognition
                if (isListening) {
                    stopBasicListening();
                } else {
                    startBasicListening();
                }
            }
        }

        // Basic speech recognition
        let recognition = null;

        function startBasicListening() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onstart = () => {
                isListening = true;
                voiceButton.classList.add('listening');
                statusText.textContent = 'Listening...';
            };

            recognition.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                addMessage('user', transcript);
                voiceButton.classList.remove('listening');
                voiceButton.classList.add('processing');
                statusText.textContent = 'Processing...';

                // Send to Claude/process locally
                await processUserInput(transcript);
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                addMessage('system', `Recognition error: ${event.error}`);
                stopBasicListening();
            };

            recognition.onend = () => {
                if (isListening) {
                    isListening = false;
                    voiceButton.classList.remove('listening');
                }
            };

            recognition.start();
        }

        function stopBasicListening() {
            if (recognition) {
                recognition.stop();
            }
            isListening = false;
            voiceButton.classList.remove('listening');
            statusText.textContent = 'Ready - tap to talk';
        }

        // Process user input and generate response (basic mode)
        async function processUserInput(text) {
            const apiKey = document.getElementById('elevenlabs-key').value;
            const voiceId = document.getElementById('voice-id').value || '21m00Tcm4TlvDq8ikWAM';
            const systemPrompt = document.getElementById('system-prompt').value;

            // For basic mode, we'll just use TTS to speak a placeholder response
            // In production, you'd call Claude API here
            const response = await generateResponse(text, systemPrompt);
            addMessage('assistant', response);

            // Speak the response using ElevenLabs TTS
            await speakText(response, apiKey, voiceId);

            voiceButton.classList.remove('processing');
            statusText.textContent = 'Ready - tap to talk';
        }

        // Generate response (placeholder - would use Claude API in production)
        async function generateResponse(userText, systemPrompt) {
            // This is a placeholder. In production, call Claude API:
            // const response = await fetch('https://api.anthropic.com/v1/messages', {...})

            const lowerText = userText.toLowerCase();

            if (lowerText.includes('task') || lowerText.includes('todo')) {
                return "I'll check your SC: Tasks project in Asana. You have several items in your To Do section. Would you like me to list them, or should I create a new task?";
            } else if (lowerText.includes('project')) {
                return "Looking at your SC: Projects board. You have active projects in progress. Do you want a summary of what needs attention today?";
            } else if (lowerText.includes('lead') || lowerText.includes('sales')) {
                return "Checking your SC: Leads pipeline. I can see leads across different stages. Would you like me to focus on the ones needing follow-up?";
            } else if (lowerText.includes('contract')) {
                return "Your SC: Contracts project shows items in various stages. Any contracts you'd like me to check specifically?";
            } else if (lowerText.includes('status') || lowerText.includes('report')) {
                return "Here's your quick status: Tasks are syncing with Asana every 10 minutes. All 5 SuperChase projects are active. What area would you like me to dive deeper on?";
            } else {
                return `I heard: "${userText}". I can help you with tasks, projects, leads, contracts, or give you a status report. What would you like to focus on?`;
            }
        }

        // Text-to-speech using ElevenLabs
        async function speakText(text, apiKey, voiceId) {
            try {
                const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
                    method: 'POST',
                    headers: {
                        'Accept': 'audio/mpeg',
                        'Content-Type': 'application/json',
                        'xi-api-key': apiKey
                    },
                    body: JSON.stringify({
                        text: text,
                        model_id: 'eleven_turbo_v2_5',
                        voice_settings: {
                            stability: 0.5,
                            similarity_boost: 0.75
                        }
                    })
                });

                if (!response.ok) {
                    throw new Error(`TTS failed: ${response.status}`);
                }

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);

                statusDot.classList.add('speaking');
                statusText.textContent = 'Speaking...';

                audio.onended = () => {
                    statusDot.classList.remove('speaking');
                    statusText.textContent = 'Ready - tap to talk';
                    URL.revokeObjectURL(audioUrl);
                };

                await audio.play();
            } catch (error) {
                console.error('TTS error:', error);
                addMessage('system', `Speech error: ${error.message}`);
                statusText.textContent = 'Ready - tap to talk';
            }
        }

        // Update status display
        function updateStatus(status) {
            switch (status) {
                case 'listening':
                    statusText.textContent = 'Listening...';
                    voiceButton.classList.add('listening');
                    statusDot.classList.add('speaking');
                    break;
                case 'thinking':
                    statusText.textContent = 'Thinking...';
                    voiceButton.classList.remove('listening');
                    voiceButton.classList.add('processing');
                    break;
                case 'speaking':
                    statusText.textContent = 'Speaking...';
                    voiceButton.classList.remove('processing');
                    statusDot.classList.add('speaking');
                    break;
                case 'idle':
                    statusText.textContent = 'Ready - tap to talk';
                    voiceButton.classList.remove('listening', 'processing');
                    statusDot.classList.remove('speaking');
                    break;
            }
        }

        // Add message to conversation
        function addMessage(type, text) {
            const message = document.createElement('div');
            message.className = `message ${type}`;
            message.textContent = text;
            conversationEl.appendChild(message);
            conversationEl.scrollTop = conversationEl.scrollHeight;
        }

        // Visualizer animation
        function animateVisualizer() {
            if (isListening) {
                bars.forEach(bar => {
                    const height = Math.random() * 30 + 5;
                    bar.style.height = `${height}px`;
                });
            } else {
                bars.forEach(bar => {
                    bar.style.height = '10px';
                });
            }
            requestAnimationFrame(animateVisualizer);
        }

        // Event Listeners
        voiceButton.addEventListener('click', toggleListening);

        settingsToggle.addEventListener('click', () => {
            settingsPanel.classList.add('open');
        });

        closeSettings.addEventListener('click', () => {
            settingsPanel.classList.remove('open');
        });

        saveSettings.addEventListener('click', () => {
            saveSettingsToStorage();
            settingsPanel.classList.remove('open');
            initializeVoice();
        });

        // Quick actions
        document.querySelectorAll('.quick-action').forEach(btn => {
            btn.addEventListener('click', async () => {
                const prompt = btn.dataset.prompt;
                addMessage('user', prompt);

                if (conversation) {
                    // Send to conversational AI
                    await conversation.sendMessage(prompt);
                } else if (isConnected) {
                    // Process in basic mode
                    voiceButton.classList.add('processing');
                    statusText.textContent = 'Processing...';
                    await processUserInput(prompt);
                }
            });
        });

        // Initialize
        loadSettings();
        animateVisualizer();
    </script>
</body>
</html>
