<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SuperChase Voice Assistant</title>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --success: #10b981;
            --danger: #ef4444;
            --dark: #1e293b;
            --darker: #0f172a;
            --gray: #94a3b8;
            --light: #e2e8f0;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, var(--darker) 0%, var(--dark) 100%);
            color: var(--light);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        header {
            padding: 20px;
            text-align: center;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }

        header h1 {
            font-size: 1.5rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: var(--gray);
            transition: background 0.3s;
        }

        .status-dot.connected { background: var(--success); box-shadow: 0 0 10px var(--success); }
        .status-dot.speaking { background: var(--primary); animation: pulse 1s infinite; }
        .status-dot.listening { background: #f59e0b; animation: pulse 0.5s infinite; }

        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.2); opacity: 0.7; }
        }

        main {
            flex: 1;
            display: flex;
            flex-direction: column;
            padding: 20px;
            max-width: 800px;
            margin: 0 auto;
            width: 100%;
        }

        #conversation {
            flex: 1;
            overflow-y: auto;
            padding: 20px 0;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .message {
            max-width: 85%;
            padding: 15px 20px;
            border-radius: 20px;
            line-height: 1.5;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: var(--primary);
            align-self: flex-end;
            border-bottom-right-radius: 5px;
        }

        .message.assistant {
            background: rgba(255,255,255,0.1);
            align-self: flex-start;
            border-bottom-left-radius: 5px;
        }

        .message.system {
            background: rgba(245, 158, 11, 0.2);
            border: 1px solid rgba(245, 158, 11, 0.3);
            align-self: center;
            font-size: 0.9rem;
            color: var(--gray);
            text-align: center;
        }

        #voice-controls {
            padding: 30px 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        #voice-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, var(--primary) 0%, var(--primary-dark) 100%);
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 10px 40px rgba(99, 102, 241, 0.3);
        }

        #voice-button:hover { transform: scale(1.05); }
        #voice-button:active { transform: scale(0.95); }

        #voice-button.listening {
            background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
            box-shadow: 0 10px 40px rgba(245, 158, 11, 0.4);
            animation: listening 1s infinite;
        }

        @keyframes listening {
            0%, 100% { box-shadow: 0 10px 40px rgba(245, 158, 11, 0.4); }
            50% { box-shadow: 0 10px 60px rgba(245, 158, 11, 0.6); }
        }

        #voice-button.speaking {
            background: linear-gradient(135deg, var(--success) 0%, #059669 100%);
            box-shadow: 0 10px 40px rgba(16, 185, 129, 0.4);
        }

        #voice-button.processing {
            background: linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%);
        }

        #voice-button:disabled {
            background: var(--gray);
            cursor: not-allowed;
            box-shadow: none;
        }

        #status-text {
            color: var(--gray);
            font-size: 0.9rem;
        }

        #visualizer {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            height: 40px;
        }

        .bar {
            width: 4px;
            height: 10px;
            background: var(--primary);
            border-radius: 2px;
            transition: height 0.05s;
        }

        #settings-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255,255,255,0.1);
            border: none;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 10px;
            cursor: pointer;
            font-size: 1.2rem;
        }

        #settings-panel {
            position: fixed;
            top: 0;
            right: -400px;
            width: 350px;
            height: 100%;
            background: var(--darker);
            border-left: 1px solid rgba(255,255,255,0.1);
            padding: 20px;
            transition: right 0.3s;
            overflow-y: auto;
            z-index: 100;
        }

        #settings-panel.open { right: 0; }

        #settings-panel h2 {
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        #settings-panel .close-btn {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
        }

        .setting-group {
            margin-bottom: 25px;
        }

        .setting-group label {
            display: block;
            color: var(--gray);
            font-size: 0.85rem;
            margin-bottom: 8px;
        }

        .setting-group input,
        .setting-group select,
        .setting-group textarea {
            width: 100%;
            padding: 12px;
            border-radius: 8px;
            border: 1px solid rgba(255,255,255,0.2);
            background: rgba(255,255,255,0.05);
            color: white;
            font-size: 0.95rem;
        }

        .setting-group input:focus,
        .setting-group select:focus,
        .setting-group textarea:focus {
            outline: none;
            border-color: var(--primary);
        }

        .setting-group textarea {
            min-height: 120px;
            resize: vertical;
            font-family: monospace;
            font-size: 0.85rem;
        }

        .save-btn {
            width: 100%;
            padding: 15px;
            background: var(--primary);
            border: none;
            border-radius: 8px;
            color: white;
            font-weight: 600;
            cursor: pointer;
            margin-top: 20px;
        }

        .save-btn:hover { background: var(--primary-dark); }

        #quick-actions {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-bottom: 20px;
        }

        .quick-action {
            background: rgba(255,255,255,0.1);
            border: 1px solid rgba(255,255,255,0.2);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 0.85rem;
            transition: background 0.2s;
        }

        .quick-action:hover { background: rgba(255,255,255,0.2); }

        .api-status {
            padding: 10px;
            border-radius: 8px;
            margin-bottom: 15px;
            font-size: 0.85rem;
        }

        .api-status.success {
            background: rgba(16, 185, 129, 0.2);
            border: 1px solid rgba(16, 185, 129, 0.3);
            color: var(--success);
        }

        .api-status.error {
            background: rgba(239, 68, 68, 0.2);
            border: 1px solid rgba(239, 68, 68, 0.3);
            color: var(--danger);
        }

        @media (max-width: 600px) {
            #settings-panel { width: 100%; right: -100%; }
            #voice-button { width: 100px; height: 100px; font-size: 2.5rem; }
            .message { max-width: 90%; }
        }
    </style>
</head>
<body>
    <header>
        <h1>
            <span class="status-dot" id="status-dot"></span>
            SuperChase Voice
        </h1>
    </header>

    <button id="settings-toggle">‚öôÔ∏è</button>

    <main>
        <div id="conversation">
            <div class="message system">
                Enter your ElevenLabs API key in settings to start.
            </div>
        </div>

        <div id="quick-actions">
            <button class="quick-action" data-prompt="What's on my task list today?">Tasks</button>
            <button class="quick-action" data-prompt="Summarize my active projects">Projects</button>
            <button class="quick-action" data-prompt="Any leads needing follow up?">Leads</button>
            <button class="quick-action" data-prompt="What contracts are pending?">Contracts</button>
            <button class="quick-action" data-prompt="Give me a quick status report">Status</button>
        </div>

        <div id="voice-controls">
            <button id="voice-button" disabled>üé§</button>
            <div id="visualizer">
                <div class="bar"></div><div class="bar"></div><div class="bar"></div>
                <div class="bar"></div><div class="bar"></div><div class="bar"></div>
                <div class="bar"></div><div class="bar"></div><div class="bar"></div>
            </div>
            <span id="status-text">Enter API key to start</span>
        </div>
    </main>

    <div id="settings-panel">
        <h2>
            Settings
            <button class="close-btn" id="close-settings">&times;</button>
        </h2>

        <div id="api-status"></div>

        <div class="setting-group">
            <label>ElevenLabs API Key *</label>
            <input type="password" id="elevenlabs-key" placeholder="sk_...">
        </div>

        <div class="setting-group">
            <label>Voice ID</label>
            <select id="voice-id">
                <option value="JBFqnCBsd6RMkjVDRZzb">George (default)</option>
                <option value="21m00Tcm4TlvDq8ikWAM">Rachel</option>
                <option value="EXAVITQu4vr4xnSDxMaL">Bella</option>
                <option value="ErXwobaYiN019PkySvjV">Antoni</option>
                <option value="MF3mGyEYCl7XYWbV9V6O">Elli</option>
                <option value="TxGEqnHWrfWFTfGW9XjX">Josh</option>
                <option value="VR6AewLTigWG4xSOukaG">Arnold</option>
                <option value="pNInz6obpgDQGcFmaJgB">Adam</option>
                <option value="yoZ06aMxZJJ28mfd3POQ">Sam</option>
            </select>
        </div>

        <div class="setting-group">
            <label>Model</label>
            <select id="model-id">
                <option value="eleven_turbo_v2_5">Turbo v2.5 (fastest)</option>
                <option value="eleven_multilingual_v2">Multilingual v2</option>
                <option value="eleven_monolingual_v1">Monolingual v1</option>
            </select>
        </div>

        <div class="setting-group">
            <label>Claude API Key (for responses)</label>
            <input type="password" id="claude-key" placeholder="sk-ant-...">
        </div>

        <div class="setting-group">
            <label>System Prompt</label>
            <textarea id="system-prompt">You are SuperChase, Chase Pierson's AI assistant at CPTV Inc.

Context: 5 Asana projects (Tasks, Projects, Leads, Contracts, Expenses) sync with Google Sheets every 10 minutes.

Be concise in voice responses. Confirm actions briefly. You're a trusted assistant - helpful, direct, conversational.</textarea>
        </div>

        <button class="save-btn" id="save-settings">Save & Connect</button>
    </div>

    <!-- ElevenLabs SDK -->
    <script type="module">
        // Import from CDN (ES modules)
        import { ElevenLabsClient } from 'https://esm.sh/@elevenlabs/elevenlabs-js@1.0.0';

        // State
        let elevenlabs = null;
        let isConnected = false;
        let isListening = false;
        let isSpeaking = false;
        let recognition = null;
        let currentAudio = null;
        let conversationHistory = [];

        // DOM
        const voiceButton = document.getElementById('voice-button');
        const statusText = document.getElementById('status-text');
        const statusDot = document.getElementById('status-dot');
        const conversationEl = document.getElementById('conversation');
        const settingsPanel = document.getElementById('settings-panel');
        const apiStatusEl = document.getElementById('api-status');
        const bars = document.querySelectorAll('.bar');

        // System prompt for Claude
        const SUPERCHASE_CONTEXT = `You are SuperChase, an AI personal assistant for Chase Pierson at CPTV Inc.

SYSTEM CONTEXT:
- Database: Google Sheets (synced)
- Task Management: 5 Asana projects, auto-sync every 10 minutes
  - SC: Tasks (ID: 1212853758026097) - daily tasks
  - SC: Projects (ID: 1212801154266018) - larger initiatives
  - SC: Leads (ID: 1212801154275730) - sales pipeline
  - SC: Contracts (ID: 1212853758537191) - contract lifecycle
  - SC: Expenses (ID: 1212853755253572) - expense tracking

CAPABILITIES:
- Researcher Agent: Deep research, market analysis
- Implementer Agent: Code, automation, integrations
- Reviewer Agent: QA, document review
- Communicator Agent: Email drafts (need approval to send)
- Strategist Agent: Planning, priorities

VOICE BEHAVIOR:
- Keep responses under 2-3 sentences for voice
- Be conversational and natural
- Confirm actions briefly
- Ask clarifying questions when needed
- For complex topics, offer to elaborate

You're Chase's trusted assistant. Be helpful, direct, and efficient.`;

        // Load settings
        function loadSettings() {
            const saved = localStorage.getItem('superchase-voice-settings');
            if (saved) {
                const s = JSON.parse(saved);
                document.getElementById('elevenlabs-key').value = s.elevenLabsKey || '';
                document.getElementById('voice-id').value = s.voiceId || 'JBFqnCBsd6RMkjVDRZzb';
                document.getElementById('model-id').value = s.modelId || 'eleven_turbo_v2_5';
                document.getElementById('claude-key').value = s.claudeKey || '';
                document.getElementById('system-prompt').value = s.systemPrompt || SUPERCHASE_CONTEXT;

                if (s.elevenLabsKey) {
                    initializeElevenLabs();
                }
            }
        }

        // Save settings
        function saveSettings() {
            const settings = {
                elevenLabsKey: document.getElementById('elevenlabs-key').value,
                voiceId: document.getElementById('voice-id').value,
                modelId: document.getElementById('model-id').value,
                claudeKey: document.getElementById('claude-key').value,
                systemPrompt: document.getElementById('system-prompt').value
            };
            localStorage.setItem('superchase-voice-settings', JSON.stringify(settings));
        }

        // Initialize ElevenLabs
        async function initializeElevenLabs() {
            const apiKey = document.getElementById('elevenlabs-key').value;

            if (!apiKey) {
                showApiStatus('Enter your ElevenLabs API key', 'error');
                return;
            }

            statusText.textContent = 'Connecting...';

            try {
                elevenlabs = new ElevenLabsClient({ apiKey });

                // Test connection by getting voices
                const voices = await elevenlabs.voices.getAll();
                console.log('Connected! Available voices:', voices);

                isConnected = true;
                voiceButton.disabled = false;
                statusDot.classList.add('connected');
                statusText.textContent = 'Ready - tap to talk';
                showApiStatus(`Connected! ${voices.voices?.length || 0} voices available`, 'success');

                addMessage('system', 'Connected to ElevenLabs. Tap the microphone and speak.');

                // Initialize speech recognition
                initSpeechRecognition();

            } catch (error) {
                console.error('ElevenLabs init error:', error);
                showApiStatus(`Connection failed: ${error.message}`, 'error');
                statusText.textContent = 'Connection failed';
            }
        }

        // Show API status
        function showApiStatus(message, type) {
            apiStatusEl.textContent = message;
            apiStatusEl.className = `api-status ${type}`;
        }

        // Initialize browser speech recognition
        function initSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                addMessage('system', 'Speech recognition not supported. Try Chrome or Edge.');
                return;
            }

            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                isListening = true;
                voiceButton.classList.add('listening');
                statusDot.classList.add('listening');
                statusText.textContent = 'Listening...';
            };

            recognition.onresult = (event) => {
                const transcript = Array.from(event.results)
                    .map(r => r[0].transcript)
                    .join('');

                if (event.results[0].isFinal) {
                    handleUserInput(transcript);
                }
            };

            recognition.onerror = (event) => {
                console.error('Speech error:', event.error);
                if (event.error !== 'no-speech') {
                    addMessage('system', `Speech error: ${event.error}`);
                }
                stopListening();
            };

            recognition.onend = () => {
                if (isListening && !isSpeaking) {
                    stopListening();
                }
            };
        }

        // Start listening
        function startListening() {
            if (!recognition || isSpeaking) return;

            // Stop any playing audio
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }

            try {
                recognition.start();
            } catch (e) {
                console.error('Recognition start error:', e);
            }
        }

        // Stop listening
        function stopListening() {
            isListening = false;
            voiceButton.classList.remove('listening');
            statusDot.classList.remove('listening');
            if (!isSpeaking) {
                statusText.textContent = 'Ready - tap to talk';
            }

            try {
                recognition?.stop();
            } catch (e) {}
        }

        // Handle user input
        async function handleUserInput(text) {
            if (!text.trim()) return;

            stopListening();
            addMessage('user', text);

            voiceButton.classList.add('processing');
            statusText.textContent = 'Thinking...';

            // Add to conversation history
            conversationHistory.push({ role: 'user', content: text });

            try {
                // Get response from Claude (or fallback)
                const response = await getClaudeResponse(text);

                addMessage('assistant', response);
                conversationHistory.push({ role: 'assistant', content: response });

                // Speak the response
                await speakResponse(response);

            } catch (error) {
                console.error('Response error:', error);
                addMessage('system', `Error: ${error.message}`);
                voiceButton.classList.remove('processing');
                statusText.textContent = 'Ready - tap to talk';
            }
        }

        // Get response from Claude API
        async function getClaudeResponse(userText) {
            const claudeKey = document.getElementById('claude-key').value;
            const systemPrompt = document.getElementById('system-prompt').value || SUPERCHASE_CONTEXT;

            if (!claudeKey) {
                // Fallback to simple responses if no Claude key
                return getFallbackResponse(userText);
            }

            try {
                const response = await fetch('https://api.anthropic.com/v1/messages', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'x-api-key': claudeKey,
                        'anthropic-version': '2023-06-01',
                        'anthropic-dangerous-direct-browser-access': 'true'
                    },
                    body: JSON.stringify({
                        model: 'claude-sonnet-4-20250514',
                        max_tokens: 300,
                        system: systemPrompt,
                        messages: conversationHistory.slice(-10) // Last 10 messages for context
                    })
                });

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || 'Claude API error');
                }

                const data = await response.json();
                return data.content[0].text;

            } catch (error) {
                console.error('Claude error:', error);
                return getFallbackResponse(userText);
            }
        }

        // Fallback responses when Claude API not available
        function getFallbackResponse(text) {
            const lower = text.toLowerCase();

            if (lower.includes('task') || lower.includes('todo')) {
                return "I'll check your SC: Tasks project. You can view your tasks in Asana or tell me to add a new one.";
            } else if (lower.includes('project')) {
                return "Your SC: Projects board tracks larger initiatives. Want me to summarize what's active?";
            } else if (lower.includes('lead') || lower.includes('sales')) {
                return "Looking at your SC: Leads pipeline. I can help with follow-ups or lead status updates.";
            } else if (lower.includes('contract')) {
                return "Your SC: Contracts project tracks the contract lifecycle from draft to signed.";
            } else if (lower.includes('expense')) {
                return "SC: Expenses tracks pending, approved, and paid expenses. Need to log something?";
            } else if (lower.includes('status') || lower.includes('report')) {
                return "All 5 SuperChase projects are syncing. Tasks, Projects, Leads, Contracts, and Expenses are active. What area should I focus on?";
            } else if (lower.includes('hello') || lower.includes('hi')) {
                return "Hey Chase! SuperChase is ready. What can I help you with?";
            } else {
                return `Got it. I can help with tasks, projects, leads, contracts, expenses, or give you a status report. What would you like to do?`;
            }
        }

        // Speak response using ElevenLabs
        async function speakResponse(text) {
            if (!elevenlabs) return;

            const voiceId = document.getElementById('voice-id').value;
            const modelId = document.getElementById('model-id').value;

            isSpeaking = true;
            voiceButton.classList.remove('processing');
            voiceButton.classList.add('speaking');
            statusDot.classList.add('speaking');
            statusText.textContent = 'Speaking...';

            try {
                const audio = await elevenlabs.textToSpeech.convert(voiceId, {
                    text: text,
                    model_id: modelId,
                    output_format: 'mp3_44100_128',
                    voice_settings: {
                        stability: 0.5,
                        similarity_boost: 0.75,
                        style: 0.0,
                        use_speaker_boost: true
                    }
                });

                // Convert to blob and play
                const chunks = [];
                for await (const chunk of audio) {
                    chunks.push(chunk);
                }
                const blob = new Blob(chunks, { type: 'audio/mpeg' });
                const url = URL.createObjectURL(blob);

                currentAudio = new Audio(url);

                currentAudio.onended = () => {
                    isSpeaking = false;
                    voiceButton.classList.remove('speaking');
                    statusDot.classList.remove('speaking');
                    statusText.textContent = 'Ready - tap to talk';
                    URL.revokeObjectURL(url);
                    currentAudio = null;
                };

                currentAudio.onerror = (e) => {
                    console.error('Audio playback error:', e);
                    isSpeaking = false;
                    voiceButton.classList.remove('speaking');
                    statusText.textContent = 'Ready - tap to talk';
                };

                await currentAudio.play();

            } catch (error) {
                console.error('TTS error:', error);
                addMessage('system', `Speech error: ${error.message}`);
                isSpeaking = false;
                voiceButton.classList.remove('speaking');
                statusText.textContent = 'Ready - tap to talk';
            }
        }

        // Add message to conversation
        function addMessage(type, text) {
            const msg = document.createElement('div');
            msg.className = `message ${type}`;
            msg.textContent = text;
            conversationEl.appendChild(msg);
            conversationEl.scrollTop = conversationEl.scrollHeight;
        }

        // Visualizer animation
        function animateVisualizer() {
            bars.forEach(bar => {
                const height = isListening || isSpeaking
                    ? Math.random() * 35 + 5
                    : 10;
                bar.style.height = `${height}px`;
                bar.style.background = isListening ? '#f59e0b' : isSpeaking ? 'var(--success)' : 'var(--primary)';
            });
            requestAnimationFrame(animateVisualizer);
        }

        // Voice button click handler
        voiceButton.addEventListener('click', () => {
            if (isSpeaking) {
                // Stop speaking
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }
                isSpeaking = false;
                voiceButton.classList.remove('speaking');
                statusText.textContent = 'Ready - tap to talk';
            } else if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        });

        // Settings handlers
        document.getElementById('settings-toggle').addEventListener('click', () => {
            settingsPanel.classList.add('open');
        });

        document.getElementById('close-settings').addEventListener('click', () => {
            settingsPanel.classList.remove('open');
        });

        document.getElementById('save-settings').addEventListener('click', () => {
            saveSettings();
            settingsPanel.classList.remove('open');
            initializeElevenLabs();
        });

        // Quick actions
        document.querySelectorAll('.quick-action').forEach(btn => {
            btn.addEventListener('click', () => {
                const prompt = btn.dataset.prompt;
                handleUserInput(prompt);
            });
        });

        // Initialize
        loadSettings();
        animateVisualizer();
    </script>
</body>
</html>
